{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2581388,"sourceType":"datasetVersion","datasetId":901402}],"dockerImageVersionId":30528,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Semantic segmentation ","metadata":{}},{"cell_type":"markdown","source":"### This is a multi-class semantic segmentation problem. Let's solve it using YOLOv8","metadata":{}},{"cell_type":"code","source":"# Importing necessary libraries\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nimport pandas as pd\nimport random\nimport copy\nimport shutil\nimport numpy as np\nimport ipywidgets as widgets\nimport wandb","metadata":{"execution":{"iopub.status.busy":"2025-04-25T15:44:03.418326Z","iopub.execute_input":"2025-04-25T15:44:03.418702Z","iopub.status.idle":"2025-04-25T15:44:04.450928Z","shell.execute_reply.started":"2025-04-25T15:44:03.418670Z","shell.execute_reply":"2025-04-25T15:44:04.450124Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Installing ultralytics\n!pip install ultralytics","metadata":{"execution":{"iopub.status.busy":"2025-04-25T15:44:43.694567Z","iopub.execute_input":"2025-04-25T15:44:43.694900Z","iopub.status.idle":"2025-04-25T15:44:53.869291Z","shell.execute_reply.started":"2025-04-25T15:44:43.694875Z","shell.execute_reply":"2025-04-25T15:44:53.868353Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.116-py3-none-any.whl (984 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m984.0/984.0 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy<=2.1.1,>=1.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.23.5)\nRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.1)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.8.0.74)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.5.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.31.0)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.11.1)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.0.0)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.15.1)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.65.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.5.3)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.40.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2023.5.7)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.3.116 ultralytics-thop-2.0.14\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Creating working directories","metadata":{}},{"cell_type":"code","source":"# Defining input images path, output path, masks path and labels path\npath='/kaggle/input/cholecseg8k'\nop_path='/kaggle/working'\nrawimages_path=os.path.join(op_path, 'raw_images')\nmaskimages_path=os.path.join(op_path, 'mask_images')\nlabels_path=os.path.join(op_path, 'labels')\nos.makedirs(rawimages_path)\nos.makedirs(maskimages_path)\nos.makedirs(labels_path)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:18:34.205964Z","iopub.execute_input":"2023-10-19T09:18:34.207008Z","iopub.status.idle":"2023-10-19T09:18:34.211988Z","shell.execute_reply.started":"2023-10-19T09:18:34.206962Z","shell.execute_reply":"2023-10-19T09:18:34.211058Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Defining output train,val and test paths\nimgtrainpath = os.path.join(op_path,'images','train')\nimgvalpath=os.path.join(op_path,'images','validation')\nimgtestpath=os.path.join(op_path,'images','test')\n\nlabeltrainpath=os.path.join(op_path,'labels','train')\nlabelvalpath=os.path.join(op_path,'labels','validation')\nlabeltestpath=os.path.join(op_path,'labels','test')\n\nos.makedirs(imgtrainpath)\nos.makedirs(imgvalpath)\nos.makedirs(imgtestpath)\n\nos.makedirs(labeltrainpath)\nos.makedirs(labelvalpath)\nos.makedirs(labeltestpath)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:18:37.621362Z","iopub.execute_input":"2023-10-19T09:18:37.622113Z","iopub.status.idle":"2023-10-19T09:18:37.628205Z","shell.execute_reply.started":"2023-10-19T09:18:37.622056Z","shell.execute_reply":"2023-10-19T09:18:37.627331Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Defining progress bar for visualising progress of long processes\nprogress_bar=widgets.FloatProgress(value=0, min=0, max=100, description='Progress', \n                                   layout=widgets.Layout(width='100%'))\nprogress_bar","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:18:41.583984Z","iopub.execute_input":"2023-10-19T09:18:41.584336Z","iopub.status.idle":"2023-10-19T09:18:41.593784Z","shell.execute_reply.started":"2023-10-19T09:18:41.584308Z","shell.execute_reply":"2023-10-19T09:18:41.592842Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now we transfer raw images and their corresponding color masks to their relevant output directories. Also we calculate the total number of sub-directories, total images, raw images and mask images ","metadata":{}},{"cell_type":"code","source":"m=0 # variable for counting total sub-directories\nn=0 # variable for counting total images\no=0 # variable for counting total raw images\np=0 # variable for counting total masks\nq=0 # variable for counting total directories\nfor directory in os.listdir(path):\n    dir_path=os.path.join(path, directory)\n    m=m+len(os.listdir(dir_path))\n    q=q+1\n    for sub_dir in os.listdir(dir_path):\n        sub_dir_path=os.path.join(dir_path, sub_dir)\n        n=n+len(os.listdir(sub_dir_path))\n        for image in os.listdir(sub_dir_path):\n            src_path=os.path.join(sub_dir_path, image)\n            # Rename the image based on sub-directory to distinguish images with same names from different directories\n            newname=sub_dir+image\n            if 'mask' not in image:   # Criterion for raw image             \n                newpath=os.path.join(rawimages_path, newname)\n                dest_path=os.path.join(rawimages_path, image)\n                shutil.copy(src_path, dest_path) # Copying raw image to output directory\n                os.rename(dest_path, newpath) # Renaming raw image\n                o=o+1\n            if 'color_mask' in image:  # Criterion for color mask  \n                newpath=os.path.join(maskimages_path, newname)\n                dest_path=os.path.join(maskimages_path, image)\n                shutil.copy(src_path, dest_path) # Copying mask to output directory\n                os.rename(dest_path, newpath) # Renaming mask\n                p=p+1\n    # Updating progress bar to visualise copying and renaming of raw images and masks            \n    progress_bar.value=q/len(os.listdir(path))*100 \n","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:18:45.896123Z","iopub.execute_input":"2023-10-19T09:18:45.896451Z","iopub.status.idle":"2023-10-19T09:21:12.334289Z","shell.execute_reply.started":"2023-10-19T09:18:45.896424Z","shell.execute_reply":"2023-10-19T09:21:12.333347Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Total number of sub-directories:\", m)\nprint(\"Total number of images:\", n)\nprint(\"Total number of raw images:\", o)\nprint(\"Total number of masks:\", p)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:21:16.976182Z","iopub.execute_input":"2023-10-19T09:21:16.976504Z","iopub.status.idle":"2023-10-19T09:21:16.981539Z","shell.execute_reply.started":"2023-10-19T09:21:16.976477Z","shell.execute_reply":"2023-10-19T09:21:16.980571Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We see here that we have equal number of raw images and masks. Let's verify if all the raw images and masks have been copied","metadata":{}},{"cell_type":"code","source":"# checking if all raw images and masks have been copied successfully\nlen(os.listdir(rawimages_path)), len(os.listdir(maskimages_path))","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:21:21.126174Z","iopub.execute_input":"2023-10-19T09:21:21.12649Z","iopub.status.idle":"2023-10-19T09:21:21.146914Z","shell.execute_reply.started":"2023-10-19T09:21:21.126465Z","shell.execute_reply":"2023-10-19T09:21:21.146123Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"All images and masks have been successfully copied","metadata":{}},{"cell_type":"code","source":"# Checking first five raw images\nos.listdir(rawimages_path)[:5]","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:21:25.230879Z","iopub.execute_input":"2023-10-19T09:21:25.231585Z","iopub.status.idle":"2023-10-19T09:21:25.241838Z","shell.execute_reply.started":"2023-10-19T09:21:25.231557Z","shell.execute_reply":"2023-10-19T09:21:25.240861Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Checking first five masks\nos.listdir(maskimages_path)[:5]","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:21:26.995763Z","iopub.execute_input":"2023-10-19T09:21:26.996115Z","iopub.status.idle":"2023-10-19T09:21:27.006781Z","shell.execute_reply.started":"2023-10-19T09:21:26.996062Z","shell.execute_reply":"2023-10-19T09:21:27.006036Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We see that the raw images and masks are not sorted in order. So we need to arrange them in order to visualize them as image-mask pairs","metadata":{}},{"cell_type":"code","source":"# Sorting raw images and masks\nrawimages_list=sorted(os.listdir(rawimages_path))\nmaskimages_list=sorted(os.listdir(maskimages_path))","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:21:31.865944Z","iopub.execute_input":"2023-10-19T09:21:31.866508Z","iopub.status.idle":"2023-10-19T09:21:31.884517Z","shell.execute_reply.started":"2023-10-19T09:21:31.866478Z","shell.execute_reply":"2023-10-19T09:21:31.883889Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Checking first five sorted raw images\nrawimages_list[:5]","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:21:35.500811Z","iopub.execute_input":"2023-10-19T09:21:35.501153Z","iopub.status.idle":"2023-10-19T09:21:35.506541Z","shell.execute_reply.started":"2023-10-19T09:21:35.501124Z","shell.execute_reply":"2023-10-19T09:21:35.505721Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Checking first five sorted masks\nmaskimages_list[:5]","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:21:37.296134Z","iopub.execute_input":"2023-10-19T09:21:37.29689Z","iopub.status.idle":"2023-10-19T09:21:37.301975Z","shell.execute_reply.started":"2023-10-19T09:21:37.296861Z","shell.execute_reply":"2023-10-19T09:21:37.301116Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"So raw images and masks are now sorted.","metadata":{}},{"cell_type":"markdown","source":"## Visualising images and masks","metadata":{}},{"cell_type":"markdown","source":"I have run some tests to find out the all the different RGB colors present in colored masks corresponding to the class labels and the raw images given in the problem description. Here I define the color-class mapping based on the result of my tests","metadata":{}},{"cell_type":"code","source":"color_class_mapping={(127, 127, 127): 0,\n                    (210, 140, 140): 1,\n                    (255, 114, 114): 2,\n                    (231, 70, 156): 3,\n                    (186, 183, 75): 4,\n                    (170, 255, 0): 5,\n                    (255, 85, 0): 6,\n                    (255, 0, 0): 7,\n                    (255, 255, 0): 8,\n                    (169, 255, 184): 9,\n                    (255, 160, 165): 10,\n                    (0, 50, 128): 11,\n                    (111, 74, 0): 12}\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:21:43.331408Z","iopub.execute_input":"2023-10-19T09:21:43.331981Z","iopub.status.idle":"2023-10-19T09:21:43.336988Z","shell.execute_reply.started":"2023-10-19T09:21:43.331949Z","shell.execute_reply":"2023-10-19T09:21:43.336119Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Similarly, class-color mapping is defined as well. It's the same mapping, just the other way around. It maps classes to their respective colors. It will be useful for post-processing the predicted image.","metadata":{}},{"cell_type":"code","source":"class_color_mapping = {class_index: color for color, class_index in color_class_mapping.items()}","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The class to name mapping as given in the problem description is as follows:","metadata":{}},{"cell_type":"code","source":"class_name_mapping={0: 'Black Background',\n                    1: 'Abdominal Wall',\n                    2: 'Liver',\n                    3: 'Gastrointestinal Tract',\n                    4: 'Fat',\n                    5: 'Grasper',\n                    6: 'Connective Tissue',\n                    7: 'Blood',\n                    8: 'Cystic Duct',\n                    9: 'L-hook Electrocautery',\n                    10: 'Gallbladder',\n                    11: 'Hepatic Vein',\n                    12: 'Liver Ligament'}","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:21:48.341187Z","iopub.execute_input":"2023-10-19T09:21:48.341748Z","iopub.status.idle":"2023-10-19T09:21:48.346033Z","shell.execute_reply.started":"2023-10-19T09:21:48.341717Z","shell.execute_reply":"2023-10-19T09:21:48.345242Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now I will write a function to display raw-image and its corresponding mask","metadata":{}},{"cell_type":"code","source":"def plot_image_and_mask():\n    figure,axis = plt.subplots(1,2,figsize=(30,30))\n    plt.axis('off')\n    k=random.randint(0, len(os.listdir(rawimages_path))-1) # choosing any random image number\n    \n    img_path=os.path.join(rawimages_path, rawimages_list[k]) # defining image path\n    mask_path=os.path.join(maskimages_path, maskimages_list[k]) # defining mask path\n    \n    img_title=os.path.basename(img_path) # extracting image filename from path\n    mask_title=os.path.basename(mask_path) # extracting mask filename from path\n    \n    # displaying image and mask\n    axis[0].imshow(cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB))\n    axis[0].set_title(img_title, fontsize=30)\n    axis[0].set_xticks([])\n    axis[0].set_yticks([])\n    axis[1].imshow(cv2.cvtColor(cv2.imread(mask_path), cv2.COLOR_BGR2RGB))\n    axis[1].set_title(mask_title, fontsize=30)\n    axis[1].set_xticks([])\n    axis[1].set_yticks([])\n\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:21:52.581252Z","iopub.execute_input":"2023-10-19T09:21:52.581951Z","iopub.status.idle":"2023-10-19T09:21:52.588178Z","shell.execute_reply.started":"2023-10-19T09:21:52.581921Z","shell.execute_reply":"2023-10-19T09:21:52.587355Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_image_and_mask()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:21:55.95129Z","iopub.execute_input":"2023-10-19T09:21:55.951791Z","iopub.status.idle":"2023-10-19T09:21:57.427565Z","shell.execute_reply.started":"2023-10-19T09:21:55.951754Z","shell.execute_reply":"2023-10-19T09:21:57.426137Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_image_and_mask()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:12.69968Z","iopub.execute_input":"2023-10-19T09:22:12.700452Z","iopub.status.idle":"2023-10-19T09:22:13.946856Z","shell.execute_reply.started":"2023-10-19T09:22:12.700416Z","shell.execute_reply":"2023-10-19T09:22:13.945879Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_image_and_mask()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:21.219296Z","iopub.execute_input":"2023-10-19T09:22:21.220232Z","iopub.status.idle":"2023-10-19T09:22:22.782757Z","shell.execute_reply.started":"2023-10-19T09:22:21.220185Z","shell.execute_reply":"2023-10-19T09:22:22.781903Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_image_and_mask()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:30.074149Z","iopub.execute_input":"2023-10-19T09:22:30.074721Z","iopub.status.idle":"2023-10-19T09:22:31.406058Z","shell.execute_reply.started":"2023-10-19T09:22:30.074694Z","shell.execute_reply":"2023-10-19T09:22:31.405123Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_image_and_mask()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:42.629123Z","iopub.execute_input":"2023-10-19T09:22:42.629887Z","iopub.status.idle":"2023-10-19T09:22:43.979971Z","shell.execute_reply.started":"2023-10-19T09:22:42.629857Z","shell.execute_reply":"2023-10-19T09:22:43.979149Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_image_and_mask()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:22:58.524025Z","iopub.execute_input":"2023-10-19T09:22:58.524882Z","iopub.status.idle":"2023-10-19T09:22:59.494415Z","shell.execute_reply.started":"2023-10-19T09:22:58.524848Z","shell.execute_reply":"2023-10-19T09:22:59.493581Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Masks visualisation with contours","metadata":{}},{"cell_type":"markdown","source":"We will find unique colors in mask and draw segmentation contours for any color present in it. Since we don't have pure black color (RGB-0,0,0) for any of the classes in masks, we will use it to draw contours.","metadata":{}},{"cell_type":"code","source":"# defining black color to draw contour on mask\nblack=(0,0,0)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:23:32.134345Z","iopub.execute_input":"2023-10-19T09:23:32.135201Z","iopub.status.idle":"2023-10-19T09:23:32.138934Z","shell.execute_reply.started":"2023-10-19T09:23:32.135168Z","shell.execute_reply":"2023-10-19T09:23:32.138021Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# function to draw contour around any random color present in the mask\ndef draw_contour_for_one_color_on_mask():\n    figure,axis = plt.subplots(1,3,figsize=(30,30))\n    plt.axis('off')\n    k=random.randint(0, len(rawimages_list)-1) # choosing any random image\n    \n    img_path=os.path.join(rawimages_path, rawimages_list[k]) # defining image path\n    img_title=os.path.basename(img_path) # extracting basename from path\n    img=cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n    \n    mask_path=os.path.join(maskimages_path, maskimages_list[k]) # defining mask path\n    mask_title='Mask' \n    mask=cv2.cvtColor(cv2.imread(mask_path), cv2.COLOR_BGR2RGB)\n    \n    mask_copy=copy.deepcopy(mask) # creating a copy of mask to draw contour\n    pixels = mask.reshape((-1, 3))\n    unique_colors = np.unique(pixels, axis=0) # getting unique colors present in mask\n    \n    #getting only those unique colors which are defined in problem\n    unique_colors_defined = [value for value in unique_colors if tuple(value) in color_class_mapping]\n    unique_colors_defined = np.array(unique_colors_defined, dtype=np.uint8)\n    total_colors=len(unique_colors_defined)\n    j=random.randint(0, total_colors-1) # selecting any random color among all the defined colors present in mask\n    color=unique_colors_defined[j]\n    # defining title for contour on mask\n    mask_copy_title='Mask with contour on ' +str(class_name_mapping[color_class_mapping[tuple(color)]])\n    \n    mask_mask = cv2.inRange(mask, color, color) # getting mask of the selcted color on the mask-image\n    contours, hrc = cv2.findContours(mask_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) # finding contours\n    cv2.drawContours(mask_copy, contours, -1, black, 4) # drawing contours\n    \n    axis[0].imshow(img) # displaying image\n    axis[0].set_title(img_title, fontsize=30)\n    axis[0].set_xticks([])\n    axis[0].set_yticks([])\n    axis[1].imshow(mask) # displaying mask \n    axis[1].set_title(mask_title, fontsize=30)\n    axis[1].set_xticks([])\n    axis[1].set_yticks([])\n    axis[2].imshow(mask_copy) # displaying copy of mask with contour \n    axis[2].set_title(mask_copy_title, fontsize=30)\n    axis[2].set_xticks([])\n    axis[2].set_yticks([])\n\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:23:36.295921Z","iopub.execute_input":"2023-10-19T09:23:36.296262Z","iopub.status.idle":"2023-10-19T09:23:36.305442Z","shell.execute_reply.started":"2023-10-19T09:23:36.296235Z","shell.execute_reply":"2023-10-19T09:23:36.30456Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"draw_contour_for_one_color_on_mask()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:23:39.555806Z","iopub.execute_input":"2023-10-19T09:23:39.55656Z","iopub.status.idle":"2023-10-19T09:23:41.439724Z","shell.execute_reply.started":"2023-10-19T09:23:39.556528Z","shell.execute_reply":"2023-10-19T09:23:41.438813Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"draw_contour_for_one_color_on_mask()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:23:49.989915Z","iopub.execute_input":"2023-10-19T09:23:49.9906Z","iopub.status.idle":"2023-10-19T09:23:51.246927Z","shell.execute_reply.started":"2023-10-19T09:23:49.99057Z","shell.execute_reply":"2023-10-19T09:23:51.246022Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"draw_contour_for_one_color_on_mask()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:23:58.604371Z","iopub.execute_input":"2023-10-19T09:23:58.604724Z","iopub.status.idle":"2023-10-19T09:24:00.256753Z","shell.execute_reply.started":"2023-10-19T09:23:58.604694Z","shell.execute_reply":"2023-10-19T09:24:00.255869Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"draw_contour_for_one_color_on_mask()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:24:09.201516Z","iopub.execute_input":"2023-10-19T09:24:09.20236Z","iopub.status.idle":"2023-10-19T09:24:10.584365Z","shell.execute_reply.started":"2023-10-19T09:24:09.202313Z","shell.execute_reply":"2023-10-19T09:24:10.5834Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"draw_contour_for_one_color_on_mask()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:24:18.014295Z","iopub.execute_input":"2023-10-19T09:24:18.014645Z","iopub.status.idle":"2023-10-19T09:24:19.690357Z","shell.execute_reply.started":"2023-10-19T09:24:18.014615Z","shell.execute_reply":"2023-10-19T09:24:19.689469Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"draw_contour_for_one_color_on_mask()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:29:01.069532Z","iopub.execute_input":"2023-10-19T09:29:01.069862Z","iopub.status.idle":"2023-10-19T09:29:02.362242Z","shell.execute_reply.started":"2023-10-19T09:29:01.069835Z","shell.execute_reply":"2023-10-19T09:29:02.361259Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"draw_contour_for_one_color_on_mask()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:29:09.800051Z","iopub.execute_input":"2023-10-19T09:29:09.80055Z","iopub.status.idle":"2023-10-19T09:29:11.569577Z","shell.execute_reply.started":"2023-10-19T09:29:09.800506Z","shell.execute_reply":"2023-10-19T09:29:11.568794Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"draw_contour_for_one_color_on_mask()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:28:51.394676Z","iopub.execute_input":"2023-10-19T09:28:51.395441Z","iopub.status.idle":"2023-10-19T09:28:53.109624Z","shell.execute_reply.started":"2023-10-19T09:28:51.395409Z","shell.execute_reply":"2023-10-19T09:28:53.108524Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"draw_contour_for_one_color_on_mask()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:29:35.689345Z","iopub.execute_input":"2023-10-19T09:29:35.689679Z","iopub.status.idle":"2023-10-19T09:29:37.398471Z","shell.execute_reply.started":"2023-10-19T09:29:35.689651Z","shell.execute_reply":"2023-10-19T09:29:37.397635Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"draw_contour_for_one_color_on_mask()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:29:49.058366Z","iopub.execute_input":"2023-10-19T09:29:49.058839Z","iopub.status.idle":"2023-10-19T09:29:50.962003Z","shell.execute_reply.started":"2023-10-19T09:29:49.058807Z","shell.execute_reply":"2023-10-19T09:29:50.961134Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Writing text file for masks","metadata":{}},{"cell_type":"markdown","source":"Now that there is a way to extract the contours, we will define a function to write text file per mask for all the contours for all the colors present in the mask. ","metadata":{}},{"cell_type":"code","source":"def write_polygon_file(class_contour_mapping, H, W, output_path, img_name):\n    coordinates={}\n    for obj in class_contour_mapping: # looping through all colors present in the mask\n        polygons = []\n        for cnt in class_contour_mapping[obj]: # looping through all contours present in the color\n            if cv2.contourArea(cnt) > 20: # neglecting very small contours\n                polygon = []\n                for point in cnt: # looping through all points present in the contour\n                    x, y = point[0]\n                    polygon.append(round(x / W, 4))\n                    polygon.append(round(y / H, 4))\n                polygons.append(polygon)\n        coordinates[obj]=polygons\n\n    # creating text file for all contours of all colors present in mask\n    with open('{}.txt'.format(os.path.join(output_path, img_name)), 'w') as f:\n        for obj in coordinates:\n            for polygon in coordinates[obj]:\n                for p_, p in enumerate(polygon):\n                    if p_ == len(polygon) - 1:  # if point is the last point in contour, need to give newline\n                        f.write('{}\\n'.format(p))\n                    elif p_ == 0: # if point is the first point in contour, need to specify color also\n                        f.write('{} {} '.format(obj, p))\n                    else: # any other point between first and last\n                        f.write('{} '.format(p))","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:33:30.535019Z","iopub.execute_input":"2023-10-19T09:33:30.535391Z","iopub.status.idle":"2023-10-19T09:33:30.542646Z","shell.execute_reply.started":"2023-10-19T09:33:30.535364Z","shell.execute_reply":"2023-10-19T09:33:30.541732Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We will now create segmentation label text files for all the masks. Let's use the progress bar again to visually check the progress of writing text files.","metadata":{}},{"cell_type":"code","source":"# Restarting the progress bar to track the progress of test label files creation\nprogress_bar.value=0\nprogress_bar","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:33:03.57376Z","iopub.execute_input":"2023-10-19T09:33:03.574126Z","iopub.status.idle":"2023-10-19T09:33:03.585062Z","shell.execute_reply.started":"2023-10-19T09:33:03.574095Z","shell.execute_reply":"2023-10-19T09:33:03.584346Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"k=0 # for counting total number of labels created\n\nfor img in maskimages_list:\n    # extracting shortened mask name (i.e mask name upto 'endo')\n    parts=img.split('_')\n    endo_index=parts.index('endo')\n    newname='_'.join(parts[:endo_index+1])\n    \n    # reading the image\n    image=cv2.cvtColor(cv2.imread(os.path.join(maskimages_path,img)), cv2.COLOR_BGR2RGB)\n    \n    # getting unique colors present in mask\n    pixels = image.reshape((-1, 3))\n    unique_colors = np.unique(pixels, axis=0) \n    \n    #getting only those unique colors which are defined in problem\n    unique_colors_defined = [value for value in unique_colors if tuple(value) in color_class_mapping]\n    unique_colors_defined = np.array(unique_colors_defined, dtype=np.uint8)\n    total_colors=len(unique_colors_defined)\n\n    H,W,_=image.shape # extracting mask dimensions\n    class_contour_mapping={}\n\n    for i in range(total_colors): # looping through all colors present in mask\n        color=unique_colors_defined[i] # extracting the color\n        class_code=color_class_mapping[tuple(color)] # getting color-code\n        mask = cv2.inRange(image, color, color) # getting mask of color on the mask-image\n        contours, hrc = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) # finding contours\n        class_contour_mapping[class_code]=contours # mapping color-code to contours\n            \n    # writing label text file    \n    write_polygon_file(class_contour_mapping, H, W, labels_path, newname)\n    k=k+1\n    \n    progress_bar.value=k/len(maskimages_list)*100    # updating progress bar\n    \nprint(\"Total number of labels created: \", k)    ","metadata":{"execution":{"iopub.status.busy":"2023-10-19T09:33:36.719876Z","iopub.execute_input":"2023-10-19T09:33:36.720235Z","iopub.status.idle":"2023-10-19T11:11:02.318283Z","shell.execute_reply.started":"2023-10-19T09:33:36.720207Z","shell.execute_reply":"2023-10-19T11:11:02.317404Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training, Validation and Test dataset","metadata":{}},{"cell_type":"markdown","source":"We will now shuffle the dataset randomly and then create training, validation and test dataset from the raw images. Let's write a function to do it.","metadata":{}},{"cell_type":"code","source":"# function to create training, validation and test dataset\ndef create_dataset(images_list):\n    random.shuffle(images_list)\n    train_images=images_list[:int(0.8*len(images_list))]\n    val_images=images_list[int(0.8*len(images_list)):int(0.9*len(images_list))]\n    test_images=images_list[int(0.9*len(images_list)):]\n    return train_images, val_images, test_images","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:11:14.517511Z","iopub.execute_input":"2023-10-19T11:11:14.517838Z","iopub.status.idle":"2023-10-19T11:11:14.523119Z","shell.execute_reply.started":"2023-10-19T11:11:14.517811Z","shell.execute_reply":"2023-10-19T11:11:14.522124Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_images, val_images, test_images=create_dataset(rawimages_list)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:11:17.166706Z","iopub.execute_input":"2023-10-19T11:11:17.167505Z","iopub.status.idle":"2023-10-19T11:11:17.175188Z","shell.execute_reply.started":"2023-10-19T11:11:17.167472Z","shell.execute_reply":"2023-10-19T11:11:17.174248Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# checking size of training, validation and test dataset\nlen(train_images), len(val_images), len(test_images)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:11:20.809357Z","iopub.execute_input":"2023-10-19T11:11:20.810017Z","iopub.status.idle":"2023-10-19T11:11:20.815442Z","shell.execute_reply.started":"2023-10-19T11:11:20.809986Z","shell.execute_reply":"2023-10-19T11:11:20.814557Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now that the dataset is bifurcated, we will write a function to create names of label files corresponding to the names of image files","metadata":{}},{"cell_type":"code","source":"# defining the extension for the text label files\nextension='.txt'","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:11:23.710388Z","iopub.execute_input":"2023-10-19T11:11:23.71071Z","iopub.status.idle":"2023-10-19T11:11:23.71457Z","shell.execute_reply.started":"2023-10-19T11:11:23.710683Z","shell.execute_reply":"2023-10-19T11:11:23.713715Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# function to extract basename from a file and add a different extension to it. \ndef change_extension(file):\n    basename=os.path.splitext(file)[0]\n    filename=basename+extension\n    return filename","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:11:35.108873Z","iopub.execute_input":"2023-10-19T11:11:35.109215Z","iopub.status.idle":"2023-10-19T11:11:35.113683Z","shell.execute_reply.started":"2023-10-19T11:11:35.109188Z","shell.execute_reply":"2023-10-19T11:11:35.112777Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# creating a list of label files corresponding to the image files for each dataset \ntrain_labels = list(map(change_extension, train_images)) \nval_labels = list(map(change_extension, val_images)) \ntest_labels = list(map(change_extension, test_images)) ","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:11:37.315479Z","iopub.execute_input":"2023-10-19T11:11:37.315817Z","iopub.status.idle":"2023-10-19T11:11:37.330782Z","shell.execute_reply.started":"2023-10-19T11:11:37.315789Z","shell.execute_reply":"2023-10-19T11:11:37.329888Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's verify the size of labels in datasets","metadata":{}},{"cell_type":"code","source":"len(train_labels), len(val_labels), len(test_labels)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:11:40.53846Z","iopub.execute_input":"2023-10-19T11:11:40.539218Z","iopub.status.idle":"2023-10-19T11:11:40.544452Z","shell.execute_reply.started":"2023-10-19T11:11:40.539188Z","shell.execute_reply":"2023-10-19T11:11:40.543603Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now that size of labels is same as that of images in training, validation and test sets, let's write functions to move images and labels to their respective directories","metadata":{}},{"cell_type":"markdown","source":"While moving the images, we also resize them to a fixed size so that all images have exactly same size.","metadata":{}},{"cell_type":"code","source":"# defining new image size for all images\nimage_size=640","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:11:43.983278Z","iopub.execute_input":"2023-10-19T11:11:43.983591Z","iopub.status.idle":"2023-10-19T11:11:43.987569Z","shell.execute_reply.started":"2023-10-19T11:11:43.983568Z","shell.execute_reply":"2023-10-19T11:11:43.98658Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# function to resize the images and copy the resized image to destination\ndef move_images(data_list, source_path, destination_path):\n    i=0\n    for file in data_list:\n        filepath=os.path.join(source_path, file)\n        finalimage_path=os.path.join(destination_path, file)\n        img_resized=cv2.resize(cv2.imread(filepath), (image_size, image_size))\n        cv2.imwrite(finalimage_path, img_resized)\n        i=i+1\n    print(\"Number of files transferred:\", i)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:11:51.520138Z","iopub.execute_input":"2023-10-19T11:11:51.520447Z","iopub.status.idle":"2023-10-19T11:11:51.525451Z","shell.execute_reply.started":"2023-10-19T11:11:51.520425Z","shell.execute_reply":"2023-10-19T11:11:51.524473Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# function to move files present in a list from source to destination\ndef move_files(data_list, source_path, destination_path):\n    i=0\n    for file in data_list:\n        filepath=os.path.join(source_path, file)\n        shutil.move(filepath, destination_path)\n        i=i+1\n    print(\"Number of files transferred:\", i)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:11:54.655516Z","iopub.execute_input":"2023-10-19T11:11:54.655827Z","iopub.status.idle":"2023-10-19T11:11:54.661361Z","shell.execute_reply.started":"2023-10-19T11:11:54.655804Z","shell.execute_reply":"2023-10-19T11:11:54.660606Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# moving training images\nmove_images(train_images, rawimages_path, imgtrainpath)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:11:58.720623Z","iopub.execute_input":"2023-10-19T11:11:58.721396Z","iopub.status.idle":"2023-10-19T11:15:14.227409Z","shell.execute_reply.started":"2023-10-19T11:11:58.721366Z","shell.execute_reply":"2023-10-19T11:15:14.226425Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# moving validation images\nmove_images(val_images, rawimages_path, imgvalpath)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:17:41.962635Z","iopub.execute_input":"2023-10-19T11:17:41.963269Z","iopub.status.idle":"2023-10-19T11:18:06.284725Z","shell.execute_reply.started":"2023-10-19T11:17:41.963236Z","shell.execute_reply":"2023-10-19T11:18:06.28383Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# moving test images\nmove_images(test_images, rawimages_path, imgtestpath)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:18:10.104816Z","iopub.execute_input":"2023-10-19T11:18:10.105485Z","iopub.status.idle":"2023-10-19T11:18:34.479121Z","shell.execute_reply.started":"2023-10-19T11:18:10.105451Z","shell.execute_reply":"2023-10-19T11:18:34.478261Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# moving train labels\nmove_files(train_labels, labels_path, labeltrainpath)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:19:00.100791Z","iopub.execute_input":"2023-10-19T11:19:00.101608Z","iopub.status.idle":"2023-10-19T11:19:00.379154Z","shell.execute_reply.started":"2023-10-19T11:19:00.101576Z","shell.execute_reply":"2023-10-19T11:19:00.378227Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# moving validation labels\nmove_files(val_labels, labels_path, labelvalpath)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:19:06.622676Z","iopub.execute_input":"2023-10-19T11:19:06.623021Z","iopub.status.idle":"2023-10-19T11:19:06.664662Z","shell.execute_reply.started":"2023-10-19T11:19:06.622993Z","shell.execute_reply":"2023-10-19T11:19:06.663755Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# moving test labels\nmove_files(test_labels, labels_path, labeltestpath)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:19:09.998463Z","iopub.execute_input":"2023-10-19T11:19:09.999134Z","iopub.status.idle":"2023-10-19T11:19:10.039084Z","shell.execute_reply.started":"2023-10-19T11:19:09.999093Z","shell.execute_reply":"2023-10-19T11:19:10.038223Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"So, all the images and labels have been moved to their respective directories. ","metadata":{}},{"cell_type":"markdown","source":"Let's have the list of test masks handy as it will be required later for visualisation ","metadata":{}},{"cell_type":"code","source":"# creating list of test masks for visualisation \ntest_masks=list(map(lambda x:os.path.splitext(x)[0]+'_color_mask.png', test_images))","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:19:15.001718Z","iopub.execute_input":"2023-10-19T11:19:15.00253Z","iopub.status.idle":"2023-10-19T11:19:15.007542Z","shell.execute_reply.started":"2023-10-19T11:19:15.002493Z","shell.execute_reply":"2023-10-19T11:19:15.006623Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now we are good to create configuration file.","metadata":{}},{"cell_type":"markdown","source":"## Creating config file","metadata":{}},{"cell_type":"markdown","source":"The config file is required to use YOLOv8 model. The names of classes present in dataset and the directories for the training, validation and test datasets are indicated in the config file.","metadata":{}},{"cell_type":"code","source":"# defining newline variable for config file\nnewline='\\n'","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:19:21.397485Z","iopub.execute_input":"2023-10-19T11:19:21.397786Z","iopub.status.idle":"2023-10-19T11:19:21.402021Z","shell.execute_reply.started":"2023-10-19T11:19:21.397764Z","shell.execute_reply":"2023-10-19T11:19:21.400971Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's define the contents of the config file.","metadata":{}},{"cell_type":"code","source":"# defining lines of config text file\n\nln_1='# Train/val/test sets'+newline # starting with a comment line\n\n# train, val and test path declaration\nln_2='train: ' +\"'\"+imgtrainpath+\"'\"+newline\nln_3='val: ' +\"'\" + imgvalpath+\"'\"+newline\nln_4='test: ' +\"'\" + imgtestpath+\"'\"+newline\nln_5=newline\n\n# names of the classes declaration\nln_6='# Classes'+newline\nln_7='names:'+newline\nln_8='  0: Black Background'+newline\nln_9='  1: Abdominal Wall'+newline\nln_10='  2: Liver'+newline\nln_11='  3: Gastrointestinal Tract'+newline\nln_12='  4: Fat'+newline\nln_13='  5: Grasper'+newline\nln_14='  6: Connective Tissue'+newline\nln_15='  7: Blood'+newline\nln_16='  8: Cystic Duct'+newline\nln_17='  9: L-hook Electrocautery'+newline\nln_18='  10: Gallbladder'+newline\nln_19='  11: Hepatic Vein'+newline\nln_20='  12: Liver Ligament'\n\n#listing all config lines\nconfig_lines=[ln_1, ln_2, ln_3, ln_4, ln_5, ln_6, ln_7, ln_8, ln_9, ln_10, ln_11, ln_12,\n             ln_13, ln_14, ln_15, ln_16, ln_17, ln_18, ln_19, ln_20]","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:19:26.580794Z","iopub.execute_input":"2023-10-19T11:19:26.581142Z","iopub.status.idle":"2023-10-19T11:19:26.587413Z","shell.execute_reply.started":"2023-10-19T11:19:26.581114Z","shell.execute_reply":"2023-10-19T11:19:26.586442Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Creating path for config file\nconfig_path=os.path.join(op_path, 'config.yaml')\nconfig_path","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:19:31.097698Z","iopub.execute_input":"2023-10-19T11:19:31.098477Z","iopub.status.idle":"2023-10-19T11:19:31.104005Z","shell.execute_reply.started":"2023-10-19T11:19:31.098444Z","shell.execute_reply":"2023-10-19T11:19:31.103211Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now, we create the config file.","metadata":{}},{"cell_type":"code","source":"# Writing config file\nwith open(config_path, 'w') as f:\n    f.writelines(config_lines)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:19:34.875771Z","iopub.execute_input":"2023-10-19T11:19:34.876603Z","iopub.status.idle":"2023-10-19T11:19:34.880699Z","shell.execute_reply.started":"2023-10-19T11:19:34.876568Z","shell.execute_reply":"2023-10-19T11:19:34.879817Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model training","metadata":{}},{"cell_type":"markdown","source":"Now we can start the training process using YOLO's pretrained model","metadata":{}},{"cell_type":"code","source":"# Using YOLO's pretrained model architecture and weights for training\nmodel=YOLO('yolov8m-seg.yaml').load('yolov8m-seg.pt')","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:19:40.484645Z","iopub.execute_input":"2023-10-19T11:19:40.484991Z","iopub.status.idle":"2023-10-19T11:19:43.279036Z","shell.execute_reply.started":"2023-10-19T11:19:40.484962Z","shell.execute_reply":"2023-10-19T11:19:43.278095Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training the model for 30 epochs; here degrees, shear and perspective are augmentation arguments\nresults=model.train(data=config_path, epochs=30, iou=0.4, conf=0.01, degrees=60, \n                    shear=30, perspective=0.0005)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T11:20:00.305733Z","iopub.execute_input":"2023-10-19T11:20:00.306288Z","iopub.status.idle":"2023-10-19T13:44:58.678183Z","shell.execute_reply.started":"2023-10-19T11:20:00.306259Z","shell.execute_reply":"2023-10-19T13:44:58.677079Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Results can be converted to a zip file using the following command which is commented right now. This zip file can be downloaded later if results are to be analysed locally","metadata":{}},{"cell_type":"code","source":"# !zip -r results.zip /kaggle/working/runs/segment/train","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's see how the training progressed with epochs by visualizing the plots","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(30,30))\ntrainingresult_path=os.path.join(op_path, 'runs', 'segment', 'train')\nresults_png=cv2.imread(os.path.join(trainingresult_path,'results.png'))\nplt.imshow(results_png)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:46:01.600262Z","iopub.execute_input":"2023-10-19T13:46:01.601271Z","iopub.status.idle":"2023-10-19T13:46:02.814618Z","shell.execute_reply.started":"2023-10-19T13:46:01.601229Z","shell.execute_reply":"2023-10-19T13:46:02.813781Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"All losses- Box loss, seg loss, class loss, dfl loss are decreasing with epochs. All metrics- Precision, Recall, mAP50 and mAP50-95 are increasing with epochs","metadata":{}},{"cell_type":"markdown","source":"## Model performance and visualisation","metadata":{}},{"cell_type":"markdown","source":"Now, we will write a function to evaluate mAP50. mAP50 is mean Average Precision at IoU=0.5. It is a metric measuring average precision of segmentation masks at IoU(Intersection over Union)=0.5","metadata":{}},{"cell_type":"code","source":"# function for evaluating model metrics map50\ndef evaluate_map50(trainedmodel, data_path, dataset='val'):\n    metrics=trainedmodel.val(data=data_path, split=dataset)\n    map50=round(metrics.seg.map50, 3)\n    print(\"The mAP of model for all images on {0} dataset is {1}\".format(dataset,map50))\n    return metrics, map50","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:46:12.017283Z","iopub.execute_input":"2023-10-19T13:46:12.017995Z","iopub.status.idle":"2023-10-19T13:46:12.022916Z","shell.execute_reply.started":"2023-10-19T13:46:12.017966Z","shell.execute_reply":"2023-10-19T13:46:12.021836Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's evaluate mAP50 on test dataset","metadata":{}},{"cell_type":"code","source":"# Evaluating test metrics\ntest_metrics, test_map50=evaluate_map50(model, config_path, dataset='test')","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:46:19.274481Z","iopub.execute_input":"2023-10-19T13:46:19.27483Z","iopub.status.idle":"2023-10-19T13:46:54.371214Z","shell.execute_reply.started":"2023-10-19T13:46:19.274802Z","shell.execute_reply":"2023-10-19T13:46:54.370299Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now we should visualise the performance of our model using some test images","metadata":{}},{"cell_type":"markdown","source":"Let's first write a function to postprocess the predicted image from the model. This is done to visualise the predicted image in custom colors.","metadata":{}},{"cell_type":"code","source":"# function to post-process predicted image with custom colors\ndef postprocess_prediction(prediction):\n    masks=[]\n    \n    #collecting all masks after coloring them\n    for i in range(len(prediction.boxes.cls)):\n        background = np.zeros_like(prediction.orig_img) # creating a black background of same size as image\n        color=class_color_mapping[int(prediction.boxes.cls[i])] # extracting custom color based on predicted class from class-color mapping \n        mask_points=prediction.masks[i].xy[0].astype(np.int32) # obtaining contours of mask from predicted image\n        cv2.fillPoly(background, [mask_points], color); # filling background with mask contour using extracted color\n        masks.append(background)\n    \n    #joining all masks such that no mask is superimposed on the previous mask but only black pixels are modified\n    for i in range(len(masks)-1):\n        zero_color_mask = np.all(masks[0] == [0, 0, 0], axis=2) # creating mask of black pixels in first mask\n        masks[0][zero_color_mask] = masks[i+1][zero_color_mask] # coloring black pixels of first mask with color of subsequent mask\n        \n    return masks[0]","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:47:09.391768Z","iopub.execute_input":"2023-10-19T13:47:09.392139Z","iopub.status.idle":"2023-10-19T13:47:09.398552Z","shell.execute_reply.started":"2023-10-19T13:47:09.392104Z","shell.execute_reply":"2023-10-19T13:47:09.397618Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# function to visualise model performance on test images\ndef visualise_model_performance():\n    plt.figure(figsize=(30,30))\n    plt.axis('off')\n    k=random.randint(0, len(test_images)-1) # choosing any random image\n    \n    test_image=os.path.join(rawimages_path, test_images[k]) # defining path of image\n    img_title=os.path.basename(test_image) # extracting basename from image path\n    img=cv2.cvtColor(cv2.imread(test_image), cv2.COLOR_BGR2RGB) # reading image\n\n    \n    test_mask=os.path.join(maskimages_path, test_masks[k]) # defining path of mask\n    mask_title=os.path.basename(test_mask) # extracting basename from mask path\n    mask=cv2.cvtColor(cv2.imread(test_mask), cv2.COLOR_BGR2RGB) # reading mask\n    \n    pred = model(test_image) # predicting on image\n    pred_plotted = pred[0].plot(boxes=False) # prediction without bounding box displayed\n    pred_plotted=cv2.cvtColor(pred_plotted, cv2.COLOR_BGR2RGB)\n    pred_title='Model Prediction' # title for prediction\n    \n    postprocessed_image=postprocess_prediction(pred[0]) # post-processing prediction\n    postprocessed_image_title='Post-processed prediction' # title for post-processed prediction\n    \n    ax=plt.subplot(2,2,1)\n    plt.imshow(img)# displaying image\n    plt.title(img_title, fontsize=30)\n    plt.xticks([])\n    plt.yticks([])\n    ax=plt.subplot(2,2,2)\n    plt.imshow(mask)# displaying mask\n    plt.title(mask_title, fontsize=30)\n    plt.xticks([])\n    plt.yticks([])\n    \n    ax=plt.subplot(2,2,3)\n    plt.imshow(pred_plotted)# displaying prediction\n    plt.title(pred_title, fontsize=30)\n    plt.xticks([])\n    plt.yticks([])\n    ax=plt.subplot(2,2,4)\n    plt.imshow(postprocessed_image)# displaying post-processed prediction\n    plt.title(postprocessed_image_title, fontsize=30)\n    plt.xticks([])\n    plt.yticks([])\n\n    plt.tight_layout()\n    plt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:51:22.276234Z","iopub.execute_input":"2023-10-19T13:51:22.276915Z","iopub.status.idle":"2023-10-19T13:51:22.285304Z","shell.execute_reply.started":"2023-10-19T13:51:22.276883Z","shell.execute_reply":"2023-10-19T13:51:22.284288Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now, let's see the predictions","metadata":{}},{"cell_type":"code","source":"visualise_model_performance()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:51:36.52228Z","iopub.execute_input":"2023-10-19T13:51:36.522606Z","iopub.status.idle":"2023-10-19T13:51:38.854113Z","shell.execute_reply.started":"2023-10-19T13:51:36.52258Z","shell.execute_reply":"2023-10-19T13:51:38.85306Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualise_model_performance()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:52:05.665443Z","iopub.execute_input":"2023-10-19T13:52:05.665795Z","iopub.status.idle":"2023-10-19T13:52:07.991807Z","shell.execute_reply.started":"2023-10-19T13:52:05.665765Z","shell.execute_reply":"2023-10-19T13:52:07.990383Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualise_model_performance()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:52:52.047485Z","iopub.execute_input":"2023-10-19T13:52:52.048214Z","iopub.status.idle":"2023-10-19T13:52:53.988844Z","shell.execute_reply.started":"2023-10-19T13:52:52.048182Z","shell.execute_reply":"2023-10-19T13:52:53.987262Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualise_model_performance()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:54:20.722847Z","iopub.execute_input":"2023-10-19T13:54:20.723217Z","iopub.status.idle":"2023-10-19T13:54:23.678297Z","shell.execute_reply.started":"2023-10-19T13:54:20.723184Z","shell.execute_reply":"2023-10-19T13:54:23.677253Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualise_model_performance()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:55:35.004054Z","iopub.execute_input":"2023-10-19T13:55:35.00492Z","iopub.status.idle":"2023-10-19T13:55:37.962541Z","shell.execute_reply.started":"2023-10-19T13:55:35.004889Z","shell.execute_reply":"2023-10-19T13:55:37.961195Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualise_model_performance()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:56:43.020593Z","iopub.execute_input":"2023-10-19T13:56:43.021322Z","iopub.status.idle":"2023-10-19T13:56:45.195116Z","shell.execute_reply.started":"2023-10-19T13:56:43.021289Z","shell.execute_reply":"2023-10-19T13:56:45.194017Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualise_model_performance()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:57:31.654461Z","iopub.execute_input":"2023-10-19T13:57:31.654806Z","iopub.status.idle":"2023-10-19T13:57:34.439288Z","shell.execute_reply.started":"2023-10-19T13:57:31.654777Z","shell.execute_reply":"2023-10-19T13:57:34.438336Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualise_model_performance()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:58:56.385171Z","iopub.execute_input":"2023-10-19T13:58:56.38554Z","iopub.status.idle":"2023-10-19T13:58:59.131802Z","shell.execute_reply.started":"2023-10-19T13:58:56.385503Z","shell.execute_reply":"2023-10-19T13:58:59.130718Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We see here the performance of YOLOv8 model on semantic segmentation. The post-processed predicted images are extremely accurate. This can be vital for computer-assisted surgery. Thanks for checking.","metadata":{}}]}